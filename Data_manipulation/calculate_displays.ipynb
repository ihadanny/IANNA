{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we read the experts_displays, and add calculate 2 new columns which are dict representation of the state. Note that the 2 calculated columns are added to experts_displays!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "#import pyreact_core.query.displays as qd\n",
    "#import pyreact.query.packets as qp\n",
    "import operator\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats, optimize, interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#init:\n",
    "actions = pd.read_csv('experts_dataset/experts_actions.tsv', sep = '\\t', escapechar='\\\\')\n",
    "displays = pd.read_csv('experts_dataset/experts_displays.tsv', sep = '\\t', escapechar='\\\\')\n",
    "data=[]\n",
    "for i in range(4):\n",
    "    df = pd.read_csv('raw_datasets/'+str(i+1)+\".tsv\", sep = '\\t', index_col=0)\n",
    "    data.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>display_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>subsession_id</th>\n",
       "      <th>display_number</th>\n",
       "      <th>data_summary</th>\n",
       "      <th>filtering</th>\n",
       "      <th>sorting</th>\n",
       "      <th>grouping</th>\n",
       "      <th>aggregations</th>\n",
       "      <th>projected_fields</th>\n",
       "      <th>session_id.1</th>\n",
       "      <th>user_id</th>\n",
       "      <th>project_id</th>\n",
       "      <th>curr_display_id</th>\n",
       "      <th>size</th>\n",
       "      <th>solution</th>\n",
       "      <th>data_layer</th>\n",
       "      <th>granularity_layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"info_line\":[0.0015997002,8149],\"eth_dst\":[0....</td>\n",
       "      <td>{\"list\": []}</td>\n",
       "      <td>{\"list\":[]}</td>\n",
       "      <td>{\"list\":[]}</td>\n",
       "      <td>null</td>\n",
       "      <td>{\"list\":[{\"field\":\"number\"},{\"field\":\"sniff_ti...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"solution\":\"I AM BEAUTIFUL!!!!!!!\",\"project_i...</td>\n",
       "      <td>{'eth_dst': {'nulls': 0.0, 'entropy': 0.034415...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"info_line\":[0.0015997002,8149],\"eth_dst\":[0....</td>\n",
       "      <td>{\"list\": []}</td>\n",
       "      <td>{\"list\":[]}</td>\n",
       "      <td>{\"list\":[{\"field\":\"eth_src\",\"groupPriority\":0}]}</td>\n",
       "      <td>null</td>\n",
       "      <td>{\"list\":[{\"field\":\"number\"},{\"field\":\"sniff_ti...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"solution\":\"I AM BEAUTIFUL!!!!!!!\",\"project_i...</td>\n",
       "      <td>{'eth_dst': {'nulls': 0.0, 'entropy': 0.034415...</td>\n",
       "      <td>{'size_mean': 4324.0, 'group_attrs': ['eth_src...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"info_line\":[0.0015997002,8149],\"eth_dst\":[0....</td>\n",
       "      <td>{\"list\": []}</td>\n",
       "      <td>{\"list\":[]}</td>\n",
       "      <td>{\"list\":[{\"field\":\"eth_src\",\"groupPriority\":0}...</td>\n",
       "      <td>null</td>\n",
       "      <td>{\"list\":[{\"field\":\"number\"},{\"field\":\"sniff_ti...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"solution\":\"I AM BEAUTIFUL!!!!!!!\",\"project_i...</td>\n",
       "      <td>{'eth_dst': {'nulls': 0.0, 'entropy': 0.034415...</td>\n",
       "      <td>{'size_mean': 47.75690607734806, 'group_attrs'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"info_line\":[0.0015997002,8149],\"eth_dst\":[0....</td>\n",
       "      <td>{\"list\": []}</td>\n",
       "      <td>{\"list\":[]}</td>\n",
       "      <td>{\"list\":[]}</td>\n",
       "      <td>null</td>\n",
       "      <td>{\"list\":[{\"field\":\"number\"},{\"field\":\"sniff_ti...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"solution\":\"Port Scan, if target answers ping...</td>\n",
       "      <td>{'eth_dst': {'nulls': 0.0, 'entropy': 0.034415...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"info_line\":[0.0015997002,8149],\"eth_dst\":[0....</td>\n",
       "      <td>{\"list\": []}</td>\n",
       "      <td>{\"list\":[]}</td>\n",
       "      <td>{\"list\":[{\"field\":\"eth_src\",\"groupPriority\":0}]}</td>\n",
       "      <td>{\"list\": [{\"field\": \"length\", \"type\": \"avg\"}]}</td>\n",
       "      <td>{\"list\":[{\"field\":\"number\"},{\"field\":\"sniff_ti...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"solution\":\"Port Scan, if target answers ping...</td>\n",
       "      <td>{'eth_dst': {'nulls': 0.0, 'entropy': 0.034415...</td>\n",
       "      <td>{'size_mean': 4324.0, 'group_attrs': ['eth_src...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   display_id  session_id  subsession_id  display_number  \\\n",
       "0           1           1            NaN             NaN   \n",
       "1           2           1            NaN             NaN   \n",
       "2           3           1            NaN             NaN   \n",
       "3           4           2            NaN             NaN   \n",
       "4           5           2            NaN             NaN   \n",
       "\n",
       "                                        data_summary     filtering  \\\n",
       "0  {\"info_line\":[0.0015997002,8149],\"eth_dst\":[0....  {\"list\": []}   \n",
       "1  {\"info_line\":[0.0015997002,8149],\"eth_dst\":[0....  {\"list\": []}   \n",
       "2  {\"info_line\":[0.0015997002,8149],\"eth_dst\":[0....  {\"list\": []}   \n",
       "3  {\"info_line\":[0.0015997002,8149],\"eth_dst\":[0....  {\"list\": []}   \n",
       "4  {\"info_line\":[0.0015997002,8149],\"eth_dst\":[0....  {\"list\": []}   \n",
       "\n",
       "       sorting                                           grouping  \\\n",
       "0  {\"list\":[]}                                        {\"list\":[]}   \n",
       "1  {\"list\":[]}   {\"list\":[{\"field\":\"eth_src\",\"groupPriority\":0}]}   \n",
       "2  {\"list\":[]}  {\"list\":[{\"field\":\"eth_src\",\"groupPriority\":0}...   \n",
       "3  {\"list\":[]}                                        {\"list\":[]}   \n",
       "4  {\"list\":[]}   {\"list\":[{\"field\":\"eth_src\",\"groupPriority\":0}]}   \n",
       "\n",
       "                                     aggregations  \\\n",
       "0                                            null   \n",
       "1                                            null   \n",
       "2                                            null   \n",
       "3                                            null   \n",
       "4  {\"list\": [{\"field\": \"length\", \"type\": \"avg\"}]}   \n",
       "\n",
       "                                    projected_fields  session_id.1  user_id  \\\n",
       "0  {\"list\":[{\"field\":\"number\"},{\"field\":\"sniff_ti...             1        1   \n",
       "1  {\"list\":[{\"field\":\"number\"},{\"field\":\"sniff_ti...             1        1   \n",
       "2  {\"list\":[{\"field\":\"number\"},{\"field\":\"sniff_ti...             1        1   \n",
       "3  {\"list\":[{\"field\":\"number\"},{\"field\":\"sniff_ti...             2        5   \n",
       "4  {\"list\":[{\"field\":\"number\"},{\"field\":\"sniff_ti...             2        5   \n",
       "\n",
       "   project_id  curr_display_id  size  \\\n",
       "0           1              NaN   NaN   \n",
       "1           1              NaN   NaN   \n",
       "2           1              NaN   NaN   \n",
       "3           1              NaN   NaN   \n",
       "4           1              NaN   NaN   \n",
       "\n",
       "                                            solution  \\\n",
       "0  {\"solution\":\"I AM BEAUTIFUL!!!!!!!\",\"project_i...   \n",
       "1  {\"solution\":\"I AM BEAUTIFUL!!!!!!!\",\"project_i...   \n",
       "2  {\"solution\":\"I AM BEAUTIFUL!!!!!!!\",\"project_i...   \n",
       "3  {\"solution\":\"Port Scan, if target answers ping...   \n",
       "4  {\"solution\":\"Port Scan, if target answers ping...   \n",
       "\n",
       "                                          data_layer  \\\n",
       "0  {'eth_dst': {'nulls': 0.0, 'entropy': 0.034415...   \n",
       "1  {'eth_dst': {'nulls': 0.0, 'entropy': 0.034415...   \n",
       "2  {'eth_dst': {'nulls': 0.0, 'entropy': 0.034415...   \n",
       "3  {'eth_dst': {'nulls': 0.0, 'entropy': 0.034415...   \n",
       "4  {'eth_dst': {'nulls': 0.0, 'entropy': 0.034415...   \n",
       "\n",
       "                                   granularity_layer  \n",
       "0                                                NaN  \n",
       "1  {'size_mean': 4324.0, 'group_attrs': ['eth_src...  \n",
       "2  {'size_mean': 47.75690607734806, 'group_attrs'...  \n",
       "3                                                NaN  \n",
       "4  {'size_mean': 4324.0, 'group_attrs': ['eth_src...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hack_min(pd_series):\n",
    "    return np.min(pd_series.dropna())\n",
    "def hack_max(pd_series):\n",
    "    return np.max(pd_series.dropna())\n",
    "\n",
    "\n",
    "INT_OPERATOR_MAP = {\n",
    "    8: operator.eq,\n",
    "    32: operator.gt,\n",
    "    64: operator.ge,\n",
    "    128: operator.lt,\n",
    "    256: operator.le,\n",
    "    512: operator.ne,\n",
    "}\n",
    "\n",
    "AGG_MAP = {\n",
    "    'sum': np.sum,\n",
    "    'count': len ,\n",
    "    'min': hack_min,#lambda x:np.nanmin(x.dropna()),\n",
    "    'max': hack_max,#lambda x:np.nanmax(x.dropna()),\n",
    "    'avg': np.mean\n",
    "}\n",
    "\n",
    "KEYS=[ 'eth_dst', 'eth_src', 'highest_layer', 'info_line',\n",
    "       'ip_dst', 'ip_src', 'length', 'number',\n",
    "        'sniff_timestamp', 'tcp_dstport', 'tcp_srcport',\n",
    "       'tcp_stream']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filtered_df(project_id,filtering_dict):\n",
    "    #Given a project_id and the filtering critria, return the corresponding DataFrame\n",
    "    #legacy:\n",
    "    filters=filtering_dict[\"list\"]\n",
    "    df=data[project_id-1].copy()\n",
    "    if filters:\n",
    "        for filt in filters:\n",
    "            field = filt[\"field\"]\n",
    "            op_num = filt[\"condition\"]\n",
    "            value = filt[\"term\"]\n",
    "            #print(field,op_num,value)\n",
    "\n",
    "            #extract the operation:\n",
    "            #print(field,op_num,value)\n",
    "            if op_num in INT_OPERATOR_MAP.keys():\n",
    "                opr = INT_OPERATOR_MAP.get(op_num)\n",
    "                value= float(value) if df[field].dtype!='O' else value\n",
    "                df = df[opr(df[field], value)]\n",
    "            else:\n",
    "                if op_num==16:\n",
    "                    df = df[df[field].str.contains(value,na=False)]\n",
    "                if op_num==2:\n",
    "                    df = df[df[field].str.startswith(value,na=False)]\n",
    "                if op_num==4:\n",
    "                    df = df[df[field].str.endswith(value,na=False)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_groupby_df(df,grouping_dict,aggregation_dict):\n",
    "    #Given a dataframe, the grouping and aggregations - result (i) the aggregated dataframe, and (ii)the groupby element\n",
    " \n",
    "    groupings=grouping_dict[\"list\"]\n",
    "    if aggregation_dict:\n",
    "        aggregations=aggregation_dict[\"list\"]\n",
    "        #print(aggregations)\n",
    "    else:\n",
    "        aggregations = None\n",
    "    grouping_attrs = [group[\"field\"] for group in groupings]\n",
    "    if not grouping_attrs:\n",
    "        return None,None\n",
    "    \n",
    "    df_gb= df.groupby(grouping_attrs)\n",
    "    \n",
    "    agg_dict={'number':len} #all group-by gets the count by default in REACT-UI\n",
    "    if aggregations: #Custom aggregations: sum,count,avg,min,max\n",
    "        for agg in aggregations:\n",
    "            agg_dict[agg['field']] = AGG_MAP.get(agg['type'])\n",
    "\n",
    "        \n",
    "    agg_df = df_gb.agg(agg_dict)\n",
    "    return df_gb,agg_df\n",
    "\n",
    "def get_df_by_row(row):\n",
    "    return get_filtered_df(row[\"project_id\"],json.loads(row[\"filtering\"]))\n",
    "\n",
    "def get_grouping_by_row(row):\n",
    "    df = get_filtered_df(row[\"project_id\"],json.loads(row[\"filtering\"]))\n",
    "    df_gb,agg_df = get_groupby_df(df,json.loads(row[\"grouping\"]),json.loads(row[\"aggregations\"]))\n",
    "    return df_gb, agg_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###MEASURES:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_column_measures(column):\n",
    "    #for each column, compute its: (1) normalized value entropy (2)Null count (3)Unique values count\n",
    "    B=20\n",
    "    u = column.nunique()\n",
    "    n = column.isnull().sum()\n",
    "    column_na=column.dropna()\n",
    "    size=len(column)\n",
    "    if column.dtype=='O':\n",
    "        h=sp.stats.entropy(column_na.value_counts().values)/np.log(len(column.dropna()))\n",
    "    else:\n",
    "        h= sp.stats.entropy(np.histogram(column_na,bins=B)[0])/np.log(B)\n",
    "    return {\"unique\":u/(size-n),\"nulls\":n/size,\"entropy\":h}\n",
    "\n",
    "def calc_data_layer(disp_row):\n",
    "    #This method take a display row, and calculate the \"data layer\" measures for each column\n",
    "    df=get_filtered_df(disp_row[\"project_id\"],json.loads(disp_row[\"filtering\"]))\n",
    "    return df[KEYS].apply(get_data_column_measures).to_dict()\n",
    "\n",
    "def get_grouping_measures(group_obj,agg_df):\n",
    "    \"\"\"\"number\" is the unique identifier of a packet, \n",
    "    therefore we use it to count the size of each group , \n",
    "    although this may feel hacky\"\"\"\n",
    "    if group_obj is None or agg_df is None:\n",
    "        return None \n",
    "    B=20\n",
    "    groups_num=len(group_obj)\n",
    "    size_var=np.var(agg_df.number/np.sum(agg_df.number))\n",
    "    size_mean = np.mean(agg_df.number)\n",
    "    group_keys=group_obj.keys\n",
    "    agg_keys=list(agg_df.keys()).remove(\"number\")\n",
    "    agg_nve_dict={}\n",
    "    if agg_keys is not None:\n",
    "        for ak in agg_keys:\n",
    "            agg_nve_dict[ak]=sp.stats.entropy(np.histogram(agg_df[ak],bins=B)[0])/np.log(B)\n",
    "    return {\"group_attrs\":group_keys,\"agg_attrs\":agg_nve_dict,\"ngroups\":groups_num,\"size_var\":size_var,\"size_mean\":size_mean}\n",
    "    \n",
    "def calc_gran_layer(disp_row):\n",
    "    #this method takes a display row, and calculates the \"granularity layer\" measures\n",
    "    group_obj,agg_df = get_grouping_by_row(disp_row)\n",
    "    return get_grouping_measures(group_obj,agg_df)\n",
    "\n",
    "#    df=get_filtered_df(disp_row[\"project_id\"],json.loads(row[\"filtering\"]))\n",
    "#    return df[KEYS].apply(get_data_column_measures).to_dict()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ihadanny/anaconda2/envs/py3k/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in log\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/ihadanny/anaconda2/envs/py3k/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \n",
      "/home/ihadanny/anaconda2/envs/py3k/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "/home/ihadanny/anaconda2/envs/py3k/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "displays.loc[:, 'data_layer'] = displays.apply(calc_data_layer, axis = 1).apply(json.dumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ihadanny/anaconda2/envs/py3k/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n"
     ]
    }
   ],
   "source": [
    "displays.loc[:, 'granularity_layer'] = displays.apply(calc_gran_layer, axis = 1).apply(json.dumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "displays.to_csv('experts_dataset/experts_displays.tsv', sep = '\\t', escapechar='\\\\')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
